{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecord Converter\n",
    "\n",
    "This notebook converts datasets from a raw collection of jpg files in a folder into a tfrecord file. It also contains functions splitting train and test.\n",
    "\n",
    "**Sources**\n",
    "\n",
    "[1] [Why Every Tensorflow Developer Should Know about TFRecord](https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/)\n",
    "\n",
    "[2] [TFRecords Guide](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T10:31:36.991472Z",
     "start_time": "2018-01-06T10:31:36.341477Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ook/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "mod_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(mod_path)\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T09:14:34.281457Z",
     "start_time": "2018-01-06T09:14:34.255463Z"
    }
   },
   "outputs": [],
   "source": [
    "def seperate_test_train(config, dataset_name=None, split=None):\n",
    "    if split is None:\n",
    "        split = config.train_test_split\n",
    "    if dataset_name is None:\n",
    "        dataset_name = config.dataset_name\n",
    "    if os.path.exists(config.train_dir) or os.path.exists(config.test_dir):\n",
    "        print('Dataset is already seperated')\n",
    "        return\n",
    "    # Create fresh train and test directories\n",
    "    os.mkdir(config.train_dir)\n",
    "    os.mkdir(config.test_dir)\n",
    "    # Get list of image paths in dataset\n",
    "    print('Splitting data in: %s' % config.dataset_path)\n",
    "    image_paths = glob.glob(os.path.join(config.dataset_path, '*.png'))\n",
    "    total_images = len(image_paths)\n",
    "    num_train = int(split * total_images)\n",
    "    num_test = total_images - num_train\n",
    "    print('There are %d images in %s. Using a %0.2f split, we get %d train and %d test' %\n",
    "         (total_images, dataset_name, split, num_train, num_test))\n",
    "    # Move each image to either the test or train folder\n",
    "    test_idx = np.random.choice(total_images, num_test) \n",
    "    for i, path in enumerate(image_paths):\n",
    "        if i in test_idx:\n",
    "            os.rename(path, os.path.join(config.test_dir, os.path.basename(path)))\n",
    "        else:\n",
    "            os.rename(path, os.path.join(config.train_dir, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T09:14:35.219037Z",
     "start_time": "2018-01-06T09:14:34.968841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data in: /home/ook/repos/gazeGAN/data/04012018_headlook\n",
      "There are 9726 images in 04012018_headlook. Using a 0.95 split, we get 9239 train and 487 test\n"
     ]
    }
   ],
   "source": [
    "seperate_test_train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T10:31:38.480929Z",
     "start_time": "2018-01-06T10:31:38.418402Z"
    }
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _extract_target(path_string, filename_regex=None):\n",
    "    # Extract the label from the image path name\n",
    "    if filename_regex is None:\n",
    "        filename_regex = config.dataset_regex\n",
    "    m = re.search(filename_regex, os.path.basename(path_string))\n",
    "    gaze_x = int(float(m.group(1))*100)\n",
    "    gaze_y = int(float(m.group(2))*100)\n",
    "    return gaze_x, gaze_y\n",
    "\n",
    "def _write_tfrecord(tf_record_filename, dataset_path, image_size=None):\n",
    "    if image_size is None:\n",
    "        image_size = (config.image_width, config.image_height)\n",
    "    writer = tf.python_io.TFRecordWriter(tf_record_filename)\n",
    "    image_paths = glob.glob(os.path.join(dataset_path, '*.png'))\n",
    "    for image_path in image_paths:\n",
    "        # Get image and label from image path\n",
    "        image_raw = Image.open(image_path)\n",
    "        image_resized = image_raw.resize(image_size)\n",
    "        img = np.array(image_resized)\n",
    "        # Remove alpha channel\n",
    "        img = img[:, :, :3]\n",
    "        img_raw = img.tostring()\n",
    "        gaze_x, gaze_y = _extract_target(image_path)\n",
    "        # Feature defines each discrete entry in the tfrecords file\n",
    "        feature={\n",
    "            'gaze_x': _int64_feature(gaze_x),\n",
    "            'gaze_y': _int64_feature(gaze_y),\n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "        }\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    \n",
    "def to_tfrecord(dataset_name):\n",
    "    # Write test and train datasets\n",
    "    _write_tfrecord(config.train_tfrecord_path, config.train_dir)\n",
    "    _write_tfrecord(config.test_tfrecord_path, config.test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T10:31:47.835741Z",
     "start_time": "2018-01-06T10:31:39.960130Z"
    }
   },
   "outputs": [],
   "source": [
    "to_tfrecord(config.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

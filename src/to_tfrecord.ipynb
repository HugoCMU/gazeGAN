{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecord Converter\n",
    "\n",
    "This notebook converts datasets from a raw collection of jpg files in a folder into a tfrecord file. It also contains functions splitting train and test.\n",
    "\n",
    "**Sources**\n",
    "\n",
    "[1] [Why Every Tensorflow Developer Should Know about TFRecord](https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/)\n",
    "\n",
    "[2] [TFRecords Guide](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T11:48:44.985863Z",
     "start_time": "2018-01-05T11:48:44.978189Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "mod_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(mod_path)\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T11:48:46.572362Z",
     "start_time": "2018-01-05T11:48:46.550673Z"
    }
   },
   "outputs": [],
   "source": [
    "def seperate_test_train(dataset_name, split=0.9):\n",
    "    dataset_path = os.path.join(config.data_dir, dataset_name)\n",
    "    train_dir = os.path.join(dataset_path, 'train')\n",
    "    test_dir = os.path.join(dataset_path, 'test')\n",
    "    if os.path.exists(train_dir) or os.path.exists(test_dir):\n",
    "        print('Dataset is already seperated')\n",
    "        return\n",
    "    # Create fresh train and test directories\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    # Get list of image paths in dataset\n",
    "    image_paths=glob.glob(os.path.join(dataset_path, '*.jpg'))\n",
    "    total_images = len(image_paths)\n",
    "    num_train = int(split * total_images)\n",
    "    num_test = total_images - num_train\n",
    "    print('There are %d images in %s. Using a %0.2f split, we get %d train and %d test' %\n",
    "         (total_images, dataset_name, split, num_train, num_test))\n",
    "    # Move each image to either the test or train folder\n",
    "    test_idx = np.random.choice(total_images, num_test) \n",
    "    for i, path in enumerate(image_paths):\n",
    "        if i in test_idx:\n",
    "            os.rename(path, os.path.join(test_dir, os.path.basename(path)))\n",
    "        else:\n",
    "            os.rename(path, os.path.join(train_dir, os.path.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T11:48:48.109415Z",
     "start_time": "2018-01-05T11:48:48.107059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already seperated\n"
     ]
    }
   ],
   "source": [
    "seperate_test_train(config.dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T12:00:41.455673Z",
     "start_time": "2018-01-05T12:00:41.399538Z"
    }
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _extract_target(path_string, filename_regex=None):\n",
    "    # Extract the label from the image path name\n",
    "    if filename_regex is None:\n",
    "        filename_regex = config.dataset_regex\n",
    "    m = re.search(filename_regex, os.path.basename(path_string))\n",
    "    gaze_x = int(float(m.group(1))*100)\n",
    "    gaze_y = int(float(m.group(2))*100)\n",
    "    return gaze_x, gaze_y\n",
    "\n",
    "def _write_tfrecord(tf_record_filename, dataset_path, image_size=None):\n",
    "    if image_size is None:\n",
    "        image_size = (config.image_width, config.image_height)\n",
    "    writer = tf.python_io.TFRecordWriter(tf_record_filename)\n",
    "    image_paths = glob.glob(os.path.join(dataset_path, '*.png'))\n",
    "    for image_path in image_paths:\n",
    "        # Get image and label from image path\n",
    "        image_raw = Image.open(image_path)\n",
    "        image_resized = image_raw.resize(image_size)\n",
    "        img = np.array(image_resized)\n",
    "        gaze_x, gaze_y = _extract_target(image_path)\n",
    "        # Convert image to string for storage in tfrecords\n",
    "        img_raw = img.tostring()\n",
    "        # Feature defines each discrete entry in the tfrecords file\n",
    "        feature={\n",
    "            'gaze_x': _int64_feature(gaze_x),\n",
    "            'gaze_y': _int64_feature(gaze_y),\n",
    "            'image_raw': _bytes_feature(img_raw)\n",
    "        }\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    \n",
    "def to_tfrecord(dataset_name):\n",
    "    dataset_path = os.path.join(config.data_dir, dataset_name)\n",
    "    train_dir = os.path.join(dataset_path, 'train')\n",
    "    test_dir = os.path.join(dataset_path, 'test')\n",
    "    # Write test and train datasets\n",
    "    _write_tfrecord(os.path.join(dataset_path, 'train.tfrecords'), train_dir)\n",
    "    _write_tfrecord(os.path.join(dataset_path, 'test.tfrecords'), test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T12:00:47.008042Z",
     "start_time": "2018-01-05T12:00:42.173243Z"
    }
   },
   "outputs": [],
   "source": [
    "to_tfrecord(config.dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
